{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48219fe4",
   "metadata": {},
   "source": [
    "CARGAR DIRECCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97a7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definimos las rutas de los archivos\n",
    "ruta_bch = 'REGISTROS_ORIGINALES/bch.csv'\n",
    "ruta_bitcoin = 'REGISTROS_ORIGINALES/bitcoin.csv'\n",
    "ruta_bnb = 'REGISTROS_ORIGINALES/bnb.csv'\n",
    "ruta_etherium = 'REGISTROS_ORIGINALES/etherium.csv'\n",
    "ruta_solana = 'REGISTROS_ORIGINALES/solana.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d8e67",
   "metadata": {},
   "source": [
    "AGREGAR COLUMNA DE TIPO DE DIVISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b107f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_moneda(ruta_origen, nombre_moneda, nombre_archivo):\n",
    "    df = pd.read_csv(ruta_origen)\n",
    "    df['moneda'] = nombre_moneda\n",
    "    ruta_destino = f'COLUMNA_NOMBRE/{nombre_archivo}'\n",
    "    df.to_csv(ruta_destino, index=False)\n",
    "\n",
    "agregar_moneda(ruta_bch, 'BCH', 'bch.csv')\n",
    "agregar_moneda(ruta_bitcoin, 'Bitcoin', 'bitcoin.csv')\n",
    "agregar_moneda(ruta_bnb, 'BNB', 'bnb.csv')\n",
    "agregar_moneda(ruta_etherium, 'Ethereum', 'etherium.csv')\n",
    "agregar_moneda(ruta_solana, 'Solana', 'solana.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684555d8",
   "metadata": {},
   "source": [
    "ESTANDARIZAR NOBRES DE COLUMNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dda83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_columnas = {\n",
    "    'timestamp': 'fecha_hora',\n",
    "    'open': 'precio_apertura',\n",
    "    'high': 'precio_maximo',\n",
    "    'low': 'precio_minimo',\n",
    "    'close': 'precio_cierre',\n",
    "    'volume': 'volumen'\n",
    "}\n",
    "\n",
    "def estandarizar_nombres_columnas(ruta_origen, nombre_archivo):\n",
    "    # Leer archivo usando pandas\n",
    "    df = pd.read_csv(ruta_origen)\n",
    "    \n",
    "    # Renombrar columnas usando el diccionario\n",
    "    df.rename(columns=nombres_columnas, inplace=True)\n",
    "    \n",
    "    # Ruta para guardar el archivo estandarizado\n",
    "    ruta_destino = f'NOMBRES_ESTANDARIZADOS/{nombre_archivo}'\n",
    "    \n",
    "    # Guardar el archivo en la carpeta nueva\n",
    "    df.to_csv(ruta_destino, index=False)\n",
    "\n",
    "archivos_modificados = ['bch.csv', 'bitcoin.csv', 'bnb.csv', 'etherium.csv', 'solana.csv']\n",
    "for archivo in archivos_modificados:\n",
    "    ruta_origen = f'COLUMNA_NOMBRE/{archivo}'\n",
    "    estandarizar_nombres_columnas(ruta_origen, archivo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a30d7e",
   "metadata": {},
   "source": [
    "UNIR DOCUMENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_estandarizados = ['bch.csv', 'bitcoin.csv', 'bnb.csv', 'etherium.csv', 'solana.csv']\n",
    "\n",
    "# Leer todos los archivos CSV y concatenarlos\n",
    "df_combinado = pd.concat([pd.read_csv(f'NOMBRES_ESTANDARIZADOS/{archivo}') \n",
    "                          for archivo in archivos_estandarizados], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado en la carpeta UNIDOS\n",
    "df_combinado.to_csv('ARCHIVOS_UNIDOS/archivos_combinados.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe88fef",
   "metadata": {},
   "source": [
    "ATOMIZAR EL ARCHIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61022df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo combinado\n",
    "df = pd.read_csv('ARCHIVOS_UNIDOS/archivos_combinados.csv')\n",
    "\n",
    "# Eliminar \"p. m.\" y \"a. m.\" de la columna fecha_hora\n",
    "df['fecha_hora'] = df['fecha_hora'].str.replace(r'\\s(p\\. m\\.|a\\. m\\.)', '', regex=True)\n",
    "\n",
    "# Convertir la columna fecha_hora a tipo datetime \n",
    "df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])\n",
    "\n",
    "# Crear nuevas columnas separadas\n",
    "df['Anio'] = df['fecha_hora'].dt.year\n",
    "df['Mes'] = df['fecha_hora'].dt.month\n",
    "df['Dia'] = df['fecha_hora'].dt.day\n",
    "df['Hora'] = df['fecha_hora'].dt.strftime('%H:%M')\n",
    "\n",
    "# Eliminar la columna fecha_hora\n",
    "df.drop(columns=['fecha_hora'], inplace=True)\n",
    "\n",
    "# Convertir todos los nombres de columnas a mayúsculas\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "# Guardar el DataFrame actualizado en un nuevo archivo\n",
    "df.to_csv('ARCHIVO_ATOMICO/ARCHIVO_ATOMIZADO.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e4dd",
   "metadata": {},
   "source": [
    "Verificación de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb5f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      " PRECIO_APERTURA    0\n",
      "PRECIO_MAXIMO      0\n",
      "PRECIO_MINIMO      0\n",
      "PRECIO_CIERRE      0\n",
      "VOLUMEN            0\n",
      "MONEDA             0\n",
      "ANIO               0\n",
      "MES                0\n",
      "DIA                0\n",
      "HORA               0\n",
      "dtype: int64\n",
      "\n",
      "Número de filas duplicadas: 0\n",
      "\n",
      "Tipos de datos por columna:\n",
      " PRECIO_APERTURA    float64\n",
      "PRECIO_MAXIMO      float64\n",
      "PRECIO_MINIMO      float64\n",
      "PRECIO_CIERRE      float64\n",
      "VOLUMEN            float64\n",
      "MONEDA              object\n",
      "ANIO                 int64\n",
      "MES                  int64\n",
      "DIA                  int64\n",
      "HORA                object\n",
      "dtype: object\n",
      "\n",
      " Todos los valores en 'VOLUMEN' son válidos (mayores o iguales a cero).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo ya combinado y atomizado\n",
    "df = pd.read_csv('ARCHIVO_ATOMICO/ARCHIVO_ATOMIZADO.csv')\n",
    "\n",
    "# Verificar valores nulos\n",
    "nulos = df.isnull().sum()\n",
    "print(\"Valores nulos por columna:\\n\", nulos)\n",
    "\n",
    "# Verificar si hay filas duplicadas\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"\\nNúmero de filas duplicadas: {duplicados}\")\n",
    "\n",
    "# Verificar tipos de datos\n",
    "tipos = df.dtypes\n",
    "print(\"\\nTipos de datos por columna:\\n\", tipos)\n",
    "\n",
    "# Validación de consistencia (ejemplo para columna de volumen)\n",
    "if (df['VOLUMEN'] < 0).any():\n",
    "    print(\"\\n Hay valores negativos en la columna 'VOLUMEN'.\")\n",
    "else:\n",
    "    print(\"\\n Todos los valores en 'VOLUMEN' son válidos (mayores o iguales a cero).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c3da8",
   "metadata": {},
   "source": [
    "CAMBIO DE MES Y DIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0a8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo actualizado con NOMBRE_DIA y NOMBRE_MES.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar archivo\n",
    "df = pd.read_csv('ARCHIVO_ATOMICO/ARCHIVO_ATOMIZADO.csv')\n",
    "\n",
    "# Normalizar campos\n",
    "df['MONEDA'] = df['MONEDA'].str.upper()\n",
    "df['MES'] = df['MES'].astype(str).str.zfill(2)\n",
    "df['DIA'] = df['DIA'].astype(str).str.zfill(2)\n",
    "\n",
    "# Crear columna FECHA\n",
    "df['FECHA'] = pd.to_datetime(df['ANIO'].astype(str) + '-' + df['MES'] + '-' + df['DIA'])\n",
    "df['HORA'] = pd.to_datetime(df['HORA'], format=\"%H:%M\").dt.time\n",
    "\n",
    "# Mapas de traducción\n",
    "dias_es = {\n",
    "    'Monday': 'Lunes',\n",
    "    'Tuesday': 'Martes',\n",
    "    'Wednesday': 'Miercoles',\n",
    "    'Thursday': 'Jueves',\n",
    "    'Friday': 'Viernes',\n",
    "    'Saturday': 'Sabado',\n",
    "    'Sunday': 'Domingo'\n",
    "}\n",
    "meses_es = {\n",
    "    'January': 'Enero',\n",
    "    'February': 'Febrero',\n",
    "    'March': 'Marzo',\n",
    "    'April': 'Abril',\n",
    "    'May': 'Mayo',\n",
    "    'June': 'Junio',\n",
    "    'July': 'Julio',\n",
    "    'August': 'Agosto',\n",
    "    'September': 'Septiembre',\n",
    "    'October': 'Octubre',\n",
    "    'November': 'Noviembre',\n",
    "    'December': 'Diciembre'\n",
    "}\n",
    "\n",
    "# Agregar nombres en español\n",
    "df['NOMBRE_DIA'] = df['FECHA'].dt.day_name().map(dias_es)\n",
    "df['NOMBRE_MES'] = df['FECHA'].dt.month_name().map(meses_es)\n",
    "\n",
    "# Eliminar columnas numéricas MES y DIA\n",
    "df.drop(columns=['MES', 'DIA'], inplace=True)\n",
    "\n",
    "# Guardar nuevo archivo\n",
    "df.to_csv('ARCHIVO_ATOMICO/ARCHIVO_ATOMIZADO_2.csv', index=False)\n",
    "print(\"Archivo actualizado con NOMBRE_DIA y NOMBRE_MES.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
